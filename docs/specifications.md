## 仕様書

- [仕様書](#仕様書)
  - [1. ランタイム](#1-ランタイム)
  - [2. OAuth スコープ](#2-oauth-スコープ)
  - [3. エンドポイント](#3-エンドポイント)
  - [4. モデル](#4-モデル)
  - [5. diff サイズ上限](#5-diff-サイズ上限)
  - [6. チャンク分割](#6-チャンク分割)
  - [7. OpenAI 呼び出し](#7-openai-呼び出し)
  - [8. ログ出力](#8-ログ出力)
  - [9. レート制限対策（GitHub）](#9-レート制限対策github)
  - [10. セキュリティ](#10-セキュリティ)
  - [11. コスト上限](#11-コスト上限)
  - [12. テスト要件](#12-テスト要件)
  - [13. 用語集](#13-用語集)


### 1. ランタイム

* Vercel **Node.js Functions**
* `maxDuration`: **300 秒**

### 2. OAuth スコープ

* `public_repo`（公開リポジトリのみを対象）

### 3. エンドポイント

* `GET /api/prs?owner=&repo=`

  * 指定リポジトリの **オープン PR 一覧** を取得
* `POST /api/review`

  * サーバが GitHub から unified **.diff** を取得し、**LLM に 1 回だけ**送信

### 4. モデル

* **o4-mini 固定**（モデル切替なし）

### 5. diff サイズ上限

* **200,000 chars**（概算 ≤ 50k tokens）
* 超過時の挙動：**HTTP 413** を返し、「PR を分割してください」とガイダンス表示

### 6. チャンク分割

* **しない**（小規模 PR 前提のため）

### 7. OpenAI 呼び出し

* 実行は **1 回**
* エラー時は **最大 2 回リトライ**（指数バックオフ）

### 8. ログ出力

* `openai.tokens_prompt`
* `openai.tokens_completion`
* `openai.cost_est_jpy`
* `github.rateRemaining`
* `github.rateResetEpoch`

### 9. レート制限対策（GitHub）

* `X-RateLimit-Remaining` が **100 未満**になったら自動バックオフ
* `X-RateLimit-Reset` を参照して再試行時刻を調整

### 10. セキュリティ

* GitHub アクセストークンはサーバ側で安全に保管（環境変数／暗号化ストレージ）
* クライアントから **diff を送らない**（4.5MB 制限回避・トークン露出防止）

### 11. コスト上限

* 1 実行あたりの概算コストを **¥50 以内**に制御
* 超過見込み時は警告を表示して確認

### 12. テスト要件

* **ユニットテスト**：API レスポンス整形、サイズ上限ガード、リトライロジック
* **E2E テスト**：OAuth → PR 一覧取得 → レビュー実行 → 結果表示
* **モックテスト**：OpenAI API をモック化して安定検証

### 13. 用語集

* **GitHub レート残量**：`X-RateLimit-Remaining`（残回数）と `X-RateLimit-Reset`（リセット時刻）で示される API 呼び出しの可用枠
